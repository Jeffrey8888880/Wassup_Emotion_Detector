{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies\n",
    "This project is inspired by Nicholas Renotte.<br>\n",
    "https://youtu.be/We1uB79Ci-w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Some Detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API rename\n",
    "https://stackoverflow.com/questions/69095372/attributeerror-module-mediapipe-python-solutions-holistic-has-no-attribute-f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,  # FACEMESH_CONTOURS    FACEMESH_TESSELATION                             \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        image = cv2.flip(image, 1)                \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks', 'index','left_hand_landmarks','pose_landmarks','pose_world_landmarks','right_hand_landmarks','segmentation_mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.5804120302200317\n",
       "y: 0.7371948957443237\n",
       "z: 0.0011571053182706237"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.face_landmarks.landmark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pose_landmarks.landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Capture Landmarks & Export to CSV\n",
    "<!--<img src=\"https://i.imgur.com/8bForKY.png\">-->\n",
    "<!--<img src=\"https://i.imgur.com/AzKNp7A.png\">-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four classes : Happy, Angry, Sad, Confused\n",
    "class_name = \"Confused\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,  # FACEMESH_CONTOURS    FACEMESH_TESSELATION                             \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass        \n",
    "        image = cv2.flip(image, 1)                \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Custom Model Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.320871</td>\n",
       "      <td>0.440296</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.337354</td>\n",
       "      <td>0.401590</td>\n",
       "      <td>-0.683410</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.346927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358842</td>\n",
       "      <td>0.406044</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361503</td>\n",
       "      <td>0.401889</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.312679</td>\n",
       "      <td>0.442175</td>\n",
       "      <td>-0.610657</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.405865</td>\n",
       "      <td>-0.590008</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.338720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348618</td>\n",
       "      <td>0.404892</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351094</td>\n",
       "      <td>0.400765</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.303981</td>\n",
       "      <td>0.442869</td>\n",
       "      <td>-0.645680</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.317151</td>\n",
       "      <td>0.406691</td>\n",
       "      <td>-0.623205</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.328715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339455</td>\n",
       "      <td>0.404705</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342020</td>\n",
       "      <td>0.400408</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.296827</td>\n",
       "      <td>0.444033</td>\n",
       "      <td>-0.598968</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.306489</td>\n",
       "      <td>0.408657</td>\n",
       "      <td>-0.582656</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325815</td>\n",
       "      <td>0.402473</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328266</td>\n",
       "      <td>0.398698</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.294585</td>\n",
       "      <td>0.444071</td>\n",
       "      <td>-0.605953</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.304705</td>\n",
       "      <td>0.409121</td>\n",
       "      <td>-0.587087</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.316098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326683</td>\n",
       "      <td>0.404507</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329131</td>\n",
       "      <td>0.400429</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  Happy  0.320871  0.440296 -0.707227  0.999934  0.337354  0.401590   \n",
       "1  Happy  0.312679  0.442175 -0.610657  0.999932  0.327722  0.405865   \n",
       "2  Happy  0.303981  0.442869 -0.645680  0.999927  0.317151  0.406691   \n",
       "3  Happy  0.296827  0.444033 -0.598968  0.999926  0.306489  0.408657   \n",
       "4  Happy  0.294585  0.444071 -0.605953  0.999924  0.304705  0.409121   \n",
       "\n",
       "         z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "0 -0.683410  0.999852  0.346927  ... -0.005292   0.0  0.358842  0.406044   \n",
       "1 -0.590008  0.999847  0.338720  ... -0.006593   0.0  0.348618  0.404892   \n",
       "2 -0.623205  0.999842  0.328715  ... -0.006027   0.0  0.339455  0.404705   \n",
       "3 -0.582656  0.999842  0.318000  ... -0.005853   0.0  0.325815  0.402473   \n",
       "4 -0.587087  0.999839  0.316098  ... -0.005239   0.0  0.326683  0.404507   \n",
       "\n",
       "       z500  v500      x501      y501      z501  v501  \n",
       "0  0.004600   0.0  0.361503  0.401889  0.004808   0.0  \n",
       "1  0.002280   0.0  0.351094  0.400765  0.002346   0.0  \n",
       "2  0.001669   0.0  0.342020  0.400408  0.001656   0.0  \n",
       "3  0.001170   0.0  0.328266  0.398698  0.001026   0.0  \n",
       "4  0.001791   0.0  0.329131  0.400429  0.001760   0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>Confused</td>\n",
       "      <td>0.465810</td>\n",
       "      <td>0.446924</td>\n",
       "      <td>-1.040633</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.491910</td>\n",
       "      <td>0.394967</td>\n",
       "      <td>-1.017811</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>0.503527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530903</td>\n",
       "      <td>0.394887</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535628</td>\n",
       "      <td>0.389012</td>\n",
       "      <td>-0.004777</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>Confused</td>\n",
       "      <td>0.487771</td>\n",
       "      <td>0.445239</td>\n",
       "      <td>-0.921864</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.514673</td>\n",
       "      <td>0.392903</td>\n",
       "      <td>-0.901528</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.524671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541810</td>\n",
       "      <td>0.391119</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546177</td>\n",
       "      <td>0.385983</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>Confused</td>\n",
       "      <td>0.498486</td>\n",
       "      <td>0.445261</td>\n",
       "      <td>-0.918767</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>0.524988</td>\n",
       "      <td>0.393437</td>\n",
       "      <td>-0.897831</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.537136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554879</td>\n",
       "      <td>0.386597</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559383</td>\n",
       "      <td>0.380807</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10308</th>\n",
       "      <td>Confused</td>\n",
       "      <td>0.516727</td>\n",
       "      <td>0.444146</td>\n",
       "      <td>-0.900058</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.540993</td>\n",
       "      <td>0.391385</td>\n",
       "      <td>-0.875349</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>0.551708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566250</td>\n",
       "      <td>0.383368</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570818</td>\n",
       "      <td>0.377644</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10309</th>\n",
       "      <td>Confused</td>\n",
       "      <td>0.532806</td>\n",
       "      <td>0.442891</td>\n",
       "      <td>-0.920850</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.554875</td>\n",
       "      <td>0.388209</td>\n",
       "      <td>-0.893296</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.564816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576994</td>\n",
       "      <td>0.380491</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581704</td>\n",
       "      <td>0.374762</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          class        x1        y1        z1        v1        x2        y2  \\\n",
       "10305  Confused  0.465810  0.446924 -1.040633  0.999927  0.491910  0.394967   \n",
       "10306  Confused  0.487771  0.445239 -0.921864  0.999890  0.514673  0.392903   \n",
       "10307  Confused  0.498486  0.445261 -0.918767  0.999845  0.524988  0.393437   \n",
       "10308  Confused  0.516727  0.444146 -0.900058  0.999826  0.540993  0.391385   \n",
       "10309  Confused  0.532806  0.442891 -0.920850  0.999801  0.554875  0.388209   \n",
       "\n",
       "             z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "10305 -1.017811  0.999769  0.503527  ... -0.021927   0.0  0.530903  0.394887   \n",
       "10306 -0.901528  0.999626  0.524671  ... -0.017670   0.0  0.541810  0.391119   \n",
       "10307 -0.897831  0.999460  0.537136  ... -0.019344   0.0  0.554879  0.386597   \n",
       "10308 -0.875349  0.999398  0.551708  ... -0.019571   0.0  0.566250  0.383368   \n",
       "10309 -0.893296  0.999326  0.564816  ... -0.018308   0.0  0.576994  0.380491   \n",
       "\n",
       "           z500  v500      x501      y501      z501  v501  \n",
       "10305 -0.004865   0.0  0.535628  0.389012 -0.004777   0.0  \n",
       "10306  0.002353   0.0  0.546177  0.385983  0.002851   0.0  \n",
       "10307 -0.000673   0.0  0.559383  0.380807 -0.000158   0.0  \n",
       "10308 -0.000398   0.0  0.570818  0.377644  0.000169   0.0  \n",
       "10309  0.000984   0.0  0.581704  0.374762  0.001578   0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10310, 2005)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Happy', 'Angry', 'Sad', 'Confused'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2244, 2005)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']=='Sad'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 2005)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']=='Angry'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3324, 2005)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']=='Happy'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2642, 2005)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']=='Confused'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3093,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test == 'Sad'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1033,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test == 'Happy'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test == 'Angry'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test == 'Confused'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1572,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train == 'Sad'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2291,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train == 'Happy'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1477,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train == 'Angry'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1877,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train == 'Confused'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7217,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()), # this line can be removed if the number of classes is more than 2\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJ-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Sad', 'Angry', ..., 'Angry', 'Happy', 'Happy'], dtype='<U8')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Evaluate and Serialize Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.774652440995797\n",
      "rc 0.8179760750080828\n",
      "rf 0.9864209505334627\n",
      "gb 0.9631425800193987\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Sad', 'Angry', ..., 'Angry', 'Happy', 'Confused'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6119         Sad\n",
       "6272         Sad\n",
       "3976       Angry\n",
       "1281       Happy\n",
       "2          Happy\n",
       "          ...   \n",
       "2071       Happy\n",
       "4622       Angry\n",
       "4820       Angry\n",
       "1847       Happy\n",
       "9676    Confused\n",
       "Name: class, Length: 3093, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the joke dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joke_dic = {\n",
    "    \"Happy\": \"Do you know\\nbefore gravity was invented,\\npeople could fly?\", \n",
    "    \"Sad\": \"Cheer up, bro!\\n\", \n",
    "    \"Angry\": \"Wassup my man,\\ndo you want to have some beef?\", \n",
    "    \"Confused\":\"You seem confused;\\nare you Confucian?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confused [0.09 0.46 0.24 0.21]\n",
      "Confused [0.07 0.48 0.23 0.22]\n",
      "Confused [0.08 0.48 0.23 0.21]\n",
      "Confused [0.06 0.46 0.2  0.28]\n",
      "Sad [0.09 0.1  0.04 0.77]\n",
      "Sad [0.05 0.14 0.05 0.76]\n",
      "Sad [0.04 0.11 0.05 0.8 ]\n",
      "Sad [0.06 0.11 0.1  0.73]\n",
      "Sad [0.07 0.14 0.1  0.69]\n",
      "Sad [0.15 0.17 0.08 0.6 ]\n",
      "Sad [0.14 0.14 0.1  0.62]\n",
      "Sad [0.12 0.05 0.16 0.67]\n",
      "Sad [0.16 0.04 0.2  0.6 ]\n",
      "Sad [0.15 0.04 0.39 0.42]\n",
      "Sad [0.16 0.02 0.39 0.43]\n",
      "Sad [0.17 0.02 0.37 0.44]\n",
      "Sad [0.15 0.02 0.31 0.52]\n",
      "Sad [0.15 0.03 0.34 0.48]\n",
      "Sad [0.12 0.03 0.38 0.47]\n",
      "Sad [0.12 0.04 0.38 0.46]\n",
      "Sad [0.05 0.07 0.34 0.54]\n",
      "Sad [0.07 0.09 0.38 0.46]\n",
      "Sad [0.04 0.11 0.3  0.55]\n",
      "Sad [0.06 0.13 0.28 0.53]\n",
      "Sad [0.05 0.06 0.29 0.6 ]\n",
      "Sad [0.05 0.05 0.28 0.62]\n",
      "Sad [0.08 0.05 0.28 0.59]\n",
      "Sad [0.06 0.06 0.28 0.6 ]\n",
      "Sad [0.04 0.04 0.25 0.67]\n",
      "Sad [0.06 0.05 0.25 0.64]\n",
      "Sad [0.08 0.08 0.19 0.65]\n",
      "Sad [0.06 0.07 0.28 0.59]\n",
      "Sad [0.06 0.08 0.27 0.59]\n",
      "Sad [0.05 0.09 0.31 0.55]\n",
      "Sad [0.05 0.12 0.26 0.57]\n",
      "Sad [0.03 0.12 0.33 0.52]\n",
      "Sad [0.05 0.15 0.29 0.51]\n",
      "Happy [0.06 0.13 0.41 0.4 ]\n",
      "Happy [0.04 0.12 0.49 0.35]\n",
      "Sad [0.04 0.15 0.4  0.41]\n",
      "Happy [0.06 0.2  0.51 0.23]\n",
      "Happy [0.16 0.15 0.45 0.24]\n",
      "Happy [0.15 0.13 0.57 0.15]\n",
      "Happy [0.16 0.07 0.66 0.11]\n",
      "Happy [0.15 0.06 0.71 0.08]\n",
      "Happy [0.13 0.03 0.78 0.06]\n",
      "Happy [0.07 0.01 0.91 0.01]\n",
      "Happy [0.05 0.01 0.93 0.01]\n",
      "Happy [0.03 0.   0.97 0.  ]\n",
      "Happy [0.01 0.01 0.98 0.  ]\n",
      "Happy [0.03 0.01 0.94 0.02]\n",
      "Happy [0.03 0.08 0.88 0.01]\n",
      "Happy [0.12 0.07 0.79 0.02]\n",
      "Happy [0.08 0.08 0.82 0.02]\n",
      "Happy [0.06 0.11 0.82 0.01]\n",
      "Happy [0.06 0.11 0.82 0.01]\n",
      "Happy [0.04 0.09 0.85 0.02]\n",
      "Happy [0.03 0.09 0.88 0.  ]\n",
      "Happy [0.26 0.03 0.65 0.06]\n",
      "Happy [0.11 0.08 0.8  0.01]\n",
      "Happy [0.24 0.04 0.68 0.04]\n",
      "Happy [0.18 0.06 0.75 0.01]\n",
      "Happy [0.34 0.01 0.38 0.27]\n",
      "Happy [0.31 0.02 0.47 0.2 ]\n",
      "Happy [0.21 0.09 0.66 0.04]\n",
      "Happy [0.36 0.03 0.49 0.12]\n",
      "Angry [0.51 0.03 0.19 0.27]\n",
      "Happy [0.35 0.05 0.43 0.17]\n",
      "Happy [0.23 0.04 0.63 0.1 ]\n",
      "Angry [0.46 0.06 0.32 0.16]\n",
      "Angry [0.53 0.06 0.3  0.11]\n",
      "Happy [0.38 0.06 0.53 0.03]\n",
      "Happy [0.25 0.14 0.57 0.04]\n",
      "Angry [0.48 0.11 0.23 0.18]\n",
      "Angry [0.45 0.14 0.28 0.13]\n",
      "Angry [0.36 0.15 0.28 0.21]\n",
      "Angry [0.48 0.11 0.2  0.21]\n",
      "Angry [0.48 0.07 0.34 0.11]\n",
      "Angry [0.46 0.07 0.35 0.12]\n",
      "Angry [0.54 0.11 0.28 0.07]\n",
      "Angry [0.58 0.07 0.26 0.09]\n",
      "Happy [0.35 0.14 0.47 0.04]\n",
      "Happy [0.38 0.15 0.44 0.03]\n",
      "Happy [0.24 0.22 0.53 0.01]\n",
      "Angry [0.48 0.14 0.35 0.03]\n",
      "Angry [0.44 0.13 0.4  0.03]\n",
      "Angry [0.67 0.02 0.07 0.24]\n",
      "Angry [0.59 0.02 0.04 0.35]\n",
      "Angry [0.48 0.03 0.04 0.45]\n",
      "Sad [0.42 0.   0.04 0.54]\n",
      "Sad [0.39 0.01 0.06 0.54]\n",
      "Sad [0.41 0.02 0.04 0.53]\n",
      "Angry [0.51 0.04 0.01 0.44]\n",
      "Angry [0.54 0.02 0.01 0.43]\n",
      "Angry [0.48 0.09 0.06 0.37]\n",
      "Angry [0.45 0.11 0.12 0.32]\n",
      "Sad [0.38 0.12 0.09 0.41]\n",
      "Angry [0.47 0.07 0.08 0.38]\n",
      "Angry [0.52 0.05 0.05 0.38]\n",
      "Sad [0.44 0.03 0.01 0.52]\n",
      "Angry [0.55 0.03 0.01 0.41]\n",
      "Angry [0.56 0.08 0.   0.36]\n",
      "Sad [0.42 0.09 0.01 0.48]\n",
      "Angry [0.45 0.1  0.01 0.44]\n",
      "Sad [0.43 0.06 0.02 0.49]\n",
      "Sad [0.39 0.1  0.06 0.45]\n",
      "Sad [0.37 0.15 0.06 0.42]\n",
      "Angry [0.5  0.07 0.09 0.34]\n",
      "Angry [0.57 0.05 0.04 0.34]\n",
      "Angry [0.51 0.07 0.06 0.36]\n",
      "Angry [0.51 0.09 0.08 0.32]\n",
      "Angry [0.47 0.07 0.03 0.43]\n",
      "Angry [0.47 0.06 0.04 0.43]\n",
      "Angry [0.49 0.1  0.08 0.33]\n",
      "Angry [0.55 0.06 0.03 0.36]\n",
      "Angry [0.48 0.07 0.07 0.38]\n",
      "Angry [0.52 0.06 0.06 0.36]\n",
      "Angry [0.52 0.05 0.06 0.37]\n",
      "Angry [0.53 0.04 0.03 0.4 ]\n",
      "Sad [0.39 0.06 0.04 0.51]\n",
      "Sad [0.46 0.04 0.03 0.47]\n",
      "Sad [0.42 0.07 0.05 0.46]\n",
      "Angry [0.41 0.19 0.24 0.16]\n",
      "Angry [0.37 0.23 0.32 0.08]\n",
      "Confused [0.25 0.32 0.26 0.17]\n",
      "Confused [0.25 0.35 0.28 0.12]\n",
      "Confused [0.22 0.41 0.25 0.12]\n",
      "Confused [0.28 0.35 0.17 0.2 ]\n",
      "Confused [0.34 0.35 0.12 0.19]\n",
      "Confused [0.36 0.39 0.05 0.2 ]\n",
      "Confused [0.36 0.38 0.03 0.23]\n",
      "Confused [0.31 0.35 0.03 0.31]\n",
      "Confused [0.35 0.45 0.02 0.18]\n",
      "Confused [0.28 0.43 0.05 0.24]\n",
      "Confused [0.23 0.53 0.04 0.2 ]\n",
      "Confused [0.22 0.5  0.04 0.24]\n",
      "Confused [0.24 0.58 0.02 0.16]\n",
      "Confused [0.24 0.51 0.14 0.11]\n",
      "Confused [0.21 0.53 0.06 0.2 ]\n",
      "Confused [0.22 0.49 0.07 0.22]\n",
      "Sad [0.22 0.26 0.07 0.45]\n",
      "Sad [0.21 0.   0.13 0.66]\n",
      "Sad [0.24 0.02 0.04 0.7 ]\n",
      "Sad [0.18 0.05 0.12 0.65]\n",
      "Sad [0.1  0.05 0.12 0.73]\n",
      "Sad [0.12 0.05 0.1  0.73]\n",
      "Sad [0.04 0.09 0.09 0.78]\n",
      "Sad [0.2  0.16 0.02 0.62]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, ### API renamed\n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "#             # Append class name \n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "#             # Export to CSV\n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row) \n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            image = cv2.flip(image, 1)  \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get Joke box\n",
    "            cv2.rectangle(image, (255,0), (535, 60), (158, 141, 185), -1)\n",
    "            joke_key = body_language_class.split(' ')[0] ### joke key is body language class\n",
    "            joke_text = joke_dic[joke_key]\n",
    "            ### Display Joke\n",
    "            y0 = 12\n",
    "            dy = 18\n",
    "            for i, line in enumerate(joke_text.split('\\n')):\n",
    "                y = y0 + i*dy\n",
    "                cv2.putText(image, line, (260, y ), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)), [640,480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
